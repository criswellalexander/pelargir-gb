{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1857473-589b-42e9-9620-977852e4b6fb",
   "metadata": {},
   "source": [
    "Alexander W. Criswell 8/5/25\n",
    "\n",
    "The idea here to implement the most bare-bones implementation of the formalism we developed at the Sprint, ignoring all realistic aspects, just so we can get the paper out without spinning our wheels on some of the finer details of Global Fit implementation. Here I am taking the bare-bones model and doing some basic optimization/acceleration before testing the model in Eryn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b530ae-83bd-4e5d-af28-28474c1ab75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import jax.numpy as jnp\n",
    "import jax.numpy as xp\n",
    "# import jax.scipy.stats as xst\n",
    "# import cupy.random as cst\n",
    "import scipy.stats as xst\n",
    "import jax; jax.config.update(\"jax_enable_x64\", True)\n",
    "from corner import corner\n",
    "import legwork as lw\n",
    "import astropy.units as u\n",
    "from tqdm import tqdm\n",
    "from math import factorial\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12f06240-d2b4-43e4-bfe3-906189c1bb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CudaDevice(id=0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb5b8809-f3da-4738-89a5-f279d1d65953",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is a very silly class to deal with how terrible the structure of jax.random is\n",
    "## we are essentially creating an object which spoofs the original scipy structure\n",
    "## and forces splitting the jax key so we don't just get the same draw repeatedly\n",
    "class jax_stat_dist():\n",
    "\n",
    "    def __init__(self,jax_module,init_key,**stat_kwargs):\n",
    "        '''\n",
    "        Class to port scipy's object-oriented functionality for statistical distributions for use with JAX's random modules.\n",
    "    \n",
    "        Arguments\n",
    "        ---------------\n",
    "        jax_module (jax.random.xxx)   : A jax.random module corresponding to one of the typical statistical distributions.\n",
    "        init_key (int or jaxprng key) : Initial random key for the distribution\n",
    "        stat_kwargs                   : Keyward arguments for the statistical distribution (loc, scale, a, b, etc.)\n",
    "        \n",
    "        '''\n",
    "\n",
    "        ## set base dist\n",
    "        self.dist = jax_module\n",
    "\n",
    "        ## set key\n",
    "        if type(init_key) is int:\n",
    "            self.key = jax.random.key(init_key)\n",
    "        else:\n",
    "            self.key = init_key\n",
    "\n",
    "        ## set kwargs\n",
    "        self.stat_kwargs = stat_kwargs\n",
    "\n",
    "        return\n",
    "\n",
    "    def draw_keys(self,N=2):\n",
    "        keys = jax.random.split(self.key,N)\n",
    "        self.key = keys[0]\n",
    "        return keys[1:]\n",
    "    \n",
    "    def rvs(self,size):\n",
    "        '''\n",
    "        Wrap the rvs function.\n",
    "        '''\n",
    "        return self.dist.rvs(self.draw_keys(N=size),size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "470d4cbd-e467-4242-bee0-3c8acab70154",
   "metadata": {},
   "outputs": [],
   "source": [
    "testwrapper = jax_stat_dist(jax.random.normal,42,loc=2,scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f133d618-fd1c-40e6-8949-1a00019977ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca32b4-3649-4fad-a293-284b168b1ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a166db54-6d26-411f-a717-0c510475f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @sync_numerical_libs\n",
    "def truncnorm(loc=0.0, scale=1.0, size=None, a=None, b=None):\n",
    "    \"\"\"Provide a vectorized truncnorm implementation that is compatible with cupy.\n",
    "\n",
    "    Adapted from https://github.com/mattkinsey/bucky/blob/master/bucky/util/distributions.py\n",
    "\n",
    "    The output is calculated by using the numpy/cupy random.normal() and\n",
    "    truncted via rejection sampling. The interface is intended to mirror\n",
    "    the scipy implementation of truncnorm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    loc:\n",
    "    scale:\n",
    "    size:\n",
    "    a:\n",
    "    b:\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    ret = jax.random.normal(loc, scale, size)\n",
    "    ret = xp.atleast_1d(ret)\n",
    "    if a is None:\n",
    "        a = xp.array(-xp.inf)\n",
    "    if b is None:\n",
    "        b = xp.array(xp.inf)\n",
    "\n",
    "    while True:\n",
    "        valid = (ret > a) & (ret < b)\n",
    "        if xp.atleast_1d(valid).all():\n",
    "            return ret\n",
    "        ret[~valid] = xp.atleast_1d(jax.random.normal(loc, scale, size))[~valid]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13296ce-4c53-4630-b2fa-7fdaf2bb7b7d",
   "metadata": {},
   "source": [
    "Some GW helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "879a810c-5a56-40f2-a539-97b451559192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mc(m_1,m_2):\n",
    "    return (m_1*m_2)**(3/5) / (m_1+m_2)**(1/5)\n",
    "def get_amp_freq(theta):\n",
    "    m_1 = theta[0]*(1*u.Msun).to(u.kg).value ## to kg\n",
    "    m_2 = theta[1]*(1*u.Msun).to(u.kg).value ## to kg\n",
    "    d_L = theta[2]*(1*u.kpc).to(u.m).value ## to m\n",
    "    a = theta[3]*(1*u.AU).to(u.m).value ## to m\n",
    "    G = 6.6743e-11 ## m^3 kg^-1 s^-2\n",
    "    c = 2.99792458e8 ## m/s\n",
    "    amp = (8/xp.sqrt(5)) * (G**2/c**4) * (m_1*m_2)/(d_L*a)\n",
    "    fgw = 1/xp.pi * xp.sqrt(G*(m_1+m_2)/a**3)\n",
    "    return amp, fgw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc74d34-3aeb-4c37-8370-9eeb85afaa4c",
   "metadata": {},
   "source": [
    "Base classes for the conditional population priors. Straightforward, will only need to be swapped for cupy distributions from here: https://docs.cupy.dev/en/stable/reference/random.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9b8669a-3a88-4441-812b-8094a23bdbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalPrior:\n",
    "    \n",
    "    '''\n",
    "    Generic class to handle the population-informed priors.\n",
    "    \n",
    "    Arguments\n",
    "    -------------\n",
    "    prior_dict (dict) : Dictionary of priors given as {'parameter_name':prior_function,...}\n",
    "    conditional_map (func) : Function which returns the population-dependent priors given in prior_dict\n",
    "                             conditioned on the current values of the population parameters given as pop_theta\n",
    "    kwargs : Any additional values needed by conditional map. These will be added as attributes of the \n",
    "             HierarchicalPrior object, such that passing keyward_1=kwarg_1 will set self.keyword_1 = kwarg_1.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,prior_dict,conditional_map,rng,**kwargs):\n",
    "        ## prior dict of the form {parameter_name:prior_func}\n",
    "        self.prior_dict = prior_dict\n",
    "        ## conditional map is a function to condition the above priors on the current values of the population priors\n",
    "        self.conditional_map = conditional_map\n",
    "        ## set rng\n",
    "        self.rng = rng\n",
    "        ## set any additional kwargs needed by conditional_map function as object attributes\n",
    "        for kw in kwargs:\n",
    "            setattr(self,kw,kwargs[kw])\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def condition(self,pop_theta):\n",
    "        \n",
    "        self.conditional_dict = self.conditional_map(pop_theta,self.prior_dict)\n",
    "        \n",
    "        return\n",
    "\n",
    "    def sample_conditional(self,N=1):\n",
    "\n",
    "        theta = xp.empty((len(self.conditional_dict.keys()),N))\n",
    "        for i, key in enumerate(self.conditional_dict.keys()):\n",
    "            theta = theta.at[i,:].set(self.conditional_dict[key].rvs(N,random_state=self.rng))\n",
    "        return theta\n",
    "        \n",
    "\n",
    "class GalacticBinaryPrior(HierarchicalPrior):\n",
    "    '''\n",
    "    Population-informed GB prior. Assumes:\n",
    "    - Gaussian-distributed masses\n",
    "    - Power-law distributed orbital separations\n",
    "    - Uniformly distributed inclinations (uniform in cos(i); not population-dependent)\n",
    "    - (for now) broad Gaussian-distributed distances (TODO: update to an analytic Galaxy model)\n",
    "    - (TODO: add sky localization parameters)\n",
    "    - (TODO: add fdot)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,rng):\n",
    "        \n",
    "        self.prior_dict = {'m_1':xst.truncnorm, ## in Msun\n",
    "                           'm_2':xst.truncnorm, ## in Msun\n",
    "                           # 'd_L':st.truncnorm, ## in kpc\n",
    "                           'd_L':xst.gamma, ## in kpc\n",
    "                           'a':xst.powerlaw ## in AU\n",
    "        }\n",
    "        \n",
    "        ## set minimum allowed distance in kpc\n",
    "        self.d_min = 1e-3 ## no GBs closer than the closest known star\n",
    "        self.a_min = 1e-4 ## no binaries with a semimajor axis comparable to their radius\n",
    "        self.a_max = 1e-2 ## no binaries outside of LISA's frequency range\n",
    "        self.m_min = 0.17 ## lowest-mass observed white dwarf\n",
    "        self.m_max = 1.44 ## no WDs with mass above the Chandrasekar limit\n",
    "\n",
    "        ## store rng\n",
    "        self.rng = rng\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def condition(self,pop_theta):\n",
    "        '''\n",
    "        Condition the resolved GB parameters on the population parameters.\n",
    "        \n",
    "        Arguments:\n",
    "        ---------------\n",
    "        pop_theta (dict) : The population parameter chains as produced by Eryn. Keys are population parameter names.\n",
    "        '''\n",
    "        \n",
    "        self.conditional_dict = {}\n",
    "        ## condition mass prior on current pop values for the mean and standard deviation\n",
    "        #scipy's truncnorm definition truncates by the number of sigmas, not at a value\n",
    "        ## we have now changed this to just the actual truncation values since we had to redefine truncnorm\n",
    "        m_trunc_low = (self.m_min - pop_theta['m_mu'][-1]) #/pop_theta['m_sigma'][-1]\n",
    "        m_trunc_high = (self.m_max - pop_theta['m_mu'][-1]) #/pop_theta['m_sigma'][-1]\n",
    "        self.conditional_dict['m_1'] = self.prior_dict['m_1'](a=m_trunc_low,\n",
    "                                                              b=m_trunc_high,\n",
    "                                                              loc=pop_theta['m_mu'][-1],\n",
    "                                                              scale=pop_theta['m_sigma'][-1])\n",
    "        ## m1 and m2 should come from the same distribution; we can label-switch later if we need to assert m1>m2.\n",
    "        self.conditional_dict['m_2'] = self.prior_dict['m_2'](a=m_trunc_low,\n",
    "                                                              b=m_trunc_high,\n",
    "                                                              loc=pop_theta['m_mu'][-1],\n",
    "                                                              scale=pop_theta['m_sigma'][-1])\n",
    "        ## ensure minimum distance is preserved; \n",
    "        ## scipy's truncnorm definition truncates by the number of sigmas, not at a value\n",
    "        # d_trunc = (self.d_min - pop_theta['d_mu'][-1])/pop_theta['d_sigma'][-1] \n",
    "        # self.conditional_dict['d_L'] = self.prior_dict['d_L'](a=d_trunc,\n",
    "        #                                                       b=xp.inf,\n",
    "        #                                                       loc=pop_theta['d_mu'][-1],\n",
    "        #                                                       scale=pop_theta['d_sigma'][-1]\n",
    "        #                                                       )\n",
    "        self.conditional_dict['d_L'] = self.prior_dict['d_L'](a=pop_theta['d_gamma_a'],\n",
    "                                                              scale = pop_theta['d_gamma_b']\n",
    "                                                              )\n",
    "        ## condition semimajor axis prior\n",
    "        ## NOTE: I am defining this as p(a) ~ a^{alpha}\n",
    "        ## adding 1 because scipy defines the power law as p(a) ~ a^{alpha - 1} for some reason\n",
    "        self.conditional_dict['a'] = self.prior_dict['a'](pop_theta['a_alpha']+1,\n",
    "                                                          loc=self.a_min, ## minimum\n",
    "                                                          scale=self.a_max ## maximum\n",
    "                                                         )\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288e69a2-2a91-4cc5-b9ee-0a9944add4cb",
   "metadata": {},
   "source": [
    "Basic likelihood building blocks. This needs to be cleaned up and slimmed down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac28b7b3-2b7e-40f2-a1a5-985dc049b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make some basic faux likelihoods for the GBs\n",
    "class Likelihood():\n",
    "    '''\n",
    "    Base class for the analytic likelihood methods.\n",
    "    '''\n",
    "\n",
    "    def const_covar_gaussian_logpdf(self, theta, mu_vec, cov):\n",
    "        \"\"\"\n",
    "        Compute log N(x_i; mu_i, sigma_i) for each x_i, mu_i, sigma_i.\n",
    "        From Daniel W. on StackOverflow (https://stackoverflow.com/questions/48686934/numpy-vectorization-of-multivariate-normal)\n",
    "        Args:\n",
    "            X : shape (n, d)\n",
    "                Data points\n",
    "            means : shape (n, d)\n",
    "                Mean vectors\n",
    "            covariances : shape (n, d)\n",
    "                Diagonal covariance matrices\n",
    "        Returns:\n",
    "            logpdfs : shape (n,)\n",
    "                Log probabilities\n",
    "        \"\"\"\n",
    "        _, d = theta.shape\n",
    "        constant = d * xp.log(2 * xp.pi)\n",
    "        log_determinants = xp.log(xp.prod(xp.diag(cov)))\n",
    "        deviations = theta - mu_vec\n",
    "        inverses = 1/xp.diag(cov)\n",
    "        return -0.5 * (constant + log_determinants + xp.sum(deviations * inverses * deviations, axis=1))\n",
    "\n",
    "    def array_gaussian_logpdf(self, theta_vec, mu_vec, sigma):\n",
    "        \"\"\"\n",
    "        Compute log N(x_i; mu_i, sigma_i) for each x_i, mu_i, sigma_i.\n",
    "        From Daniel W. on StackOverflow (https://stackoverflow.com/questions/48686934/numpy-vectorization-of-multivariate-normal)\n",
    "        Args:\n",
    "            X : shape (n, d)\n",
    "                Data points\n",
    "            means : shape (n, d)\n",
    "                Mean vectors\n",
    "            covariances : shape (n, d)\n",
    "                Diagonal covariance matrices\n",
    "        Returns:\n",
    "            logpdfs : shape (n,)\n",
    "                Log probabilities\n",
    "        \"\"\"\n",
    "        # d = theta.shape\n",
    "        # constant = xp.log(2 * xp.pi)\n",
    "\n",
    "        return - xp.sum((theta_vec - mu_vec)**2)/(2*sigma)\n",
    "\n",
    "\n",
    "        \n",
    "        # log_determinants = xp.log(xp.prod(xp.diag(cov)))\n",
    "        # deviations = theta - mu_vec\n",
    "        # inverses = 1/xp.diag(cov)\n",
    "        # return -0.5 * (constant + log_determinants + xp.sum(deviations * inverses * deviations, axis=1))\n",
    "    \n",
    "    def vectorized_gaussian_logpdf(self, theta, mu_vec, cov_vec):\n",
    "        \"\"\"\n",
    "        Compute log N(x_i; mu_i, sigma_i) for each x_i, mu_i, sigma_i.\n",
    "        From Daniel W. on StackOverflow (https://stackoverflow.com/questions/48686934/numpy-vectorization-of-multivariate-normal)\n",
    "        Args:\n",
    "            X : shape (n, d)\n",
    "                Data points\n",
    "            means : shape (n, d)\n",
    "                Mean vectors\n",
    "            covariances : shape (n, d)\n",
    "                Diagonal covariance matrices\n",
    "        Returns:\n",
    "            logpdfs : shape (n,)\n",
    "                Log probabilities\n",
    "        \"\"\"\n",
    "        _, d = theta.shape\n",
    "        constant = d * xp.log(2 * xp.pi)\n",
    "        log_determinants = xp.log(xp.prod(cov_vec, axis=1))\n",
    "        deviations = theta - mu_vec\n",
    "        inverses = 1 / cov_vec\n",
    "        return -0.5 * (constant + log_determinants + xp.sum(deviations * inverses * deviations, axis=1))\n",
    "\n",
    "class GB_Likelihood(Likelihood):\n",
    "    '''\n",
    "    GB analytic likelihood class\n",
    "    '''\n",
    "\n",
    "    def __init__(self,theta_true,cov,sigma_of_f=False):\n",
    "        '''\n",
    "        theta_true are the true simulated parameter values, of shape N_res x N_theta\n",
    "        sigma is the N_theta x N_theta (N_theta x N_theta x N_f) or covariance matrix\n",
    "        sigma_of_f (bool) : Whether the provided covariance is a function of frequency\n",
    "        '''\n",
    "        \n",
    "        if not sigma_of_f:\n",
    "            ## calculate the observed means with scatter from true vals\n",
    "            self.mu_vec = xp.array([st.multivariate_normal.rvs(mean=theta_true[ii,:],\n",
    "                                                               cov=cov,size=1) for ii in range(theta_true.shape[0])])\n",
    "            self.cov = cov\n",
    "            self.ln_prob = self.ln_prob_const_sigma\n",
    "        else:\n",
    "            self.mu_vec = st.multivariate_normal.rvs(mean=theta_true,cov=cov,size=1)\n",
    "            self.cov_vec = cov\n",
    "            self.ln_prob = self.ln_prob_sigma_of_f\n",
    "            raise(NotImplementedError)\n",
    "    \n",
    "    # def ln_prob(self,theta):\n",
    "    #     return -0.5*(theta - self.mu_vec).T @ xp.inv(self.cov) @ (theta - self.mu_vec)\n",
    "    def ln_prob_const_sigma(self,theta):\n",
    "        return self.const_covar_gaussian_logpdf(theta,self.mu_vec,self.cov)\n",
    "    def ln_prob_sigma_of_f(self,theta):\n",
    "        return self.vectorized_gaussian_logpdf(theta,self.mu_vec,self.cov_vec)\n",
    "\n",
    "class Nres_Likelihood(Likelihood):\n",
    "    '''\n",
    "    N_res Poisson likelihood\n",
    "    '''\n",
    "\n",
    "    def __init__(self,N_res_obs):\n",
    "        '''\n",
    "        N_res_obs (Number of resolved binaries)\n",
    "        '''\n",
    "\n",
    "        self.N_res_obs = N_res_obs\n",
    "        self.base_dist = xst.poisson(self.N_res_obs)\n",
    "        self.ln_prob = self.ln_conditional_Poisson\n",
    "\n",
    "    # def ln_conditional_Poisson(self,N_res_theta):\n",
    "\n",
    "    #     return -self.N_res_obs + N_res_theta*xp.log(N_res_obs) - xp.log(factorial(N_res_theta))\n",
    "\n",
    "    ## okay for now, just use the scipy stats one and take the log\n",
    "    def ln_conditional_Poisson(self,N_res_theta):\n",
    "        return xp.log(self.base_dist.pmf(N_res_theta))\n",
    "\n",
    "class FG_Likelihood(Likelihood):\n",
    "    '''\n",
    "    Foreground analytic likelihood class\n",
    "    '''\n",
    "\n",
    "    def __init__(self,spec_data,cov,sigma_of_f=False):\n",
    "        '''\n",
    "        spec_data (foreground PSD)\n",
    "        cov (!! needs to be diagonal and in units of log amplitude)\n",
    "        '''\n",
    "        \n",
    "        if not sigma_of_f:\n",
    "            ## calculate the observed means with scatter from true vals\n",
    "            self.mu_vec = spec_data, #st.multivariate_normal.rvs(mean=spec_data,\n",
    "                                    # cov=cov,size=1)\n",
    "            self.cov = cov\n",
    "            self.ln_prob = self.ln_prob_const_sigma\n",
    "        else:\n",
    "            self.mu_vec = theta_true ## st.multivariate_normal.rvs(mean=theta_true,cov=cov,size=1)\n",
    "            self.cov_vec = cov\n",
    "            self.ln_prob = self.ln_prob_sigma_of_f\n",
    "            raise(NotImplementedError)\n",
    "    \n",
    "    # def ln_prob(self,theta):\n",
    "    #     return -0.5*(theta - self.mu_vec).T @ xp.inv(self.cov) @ (theta - self.mu_vec)\n",
    "    def ln_prob_const_sigma(self,theta_spec):\n",
    "        return self.array_gaussian_logpdf(xp.log10(theta_spec),xp.log10(self.mu_vec),self.cov)\n",
    "    def ln_prob_sigma_of_f(self,theta_spec):\n",
    "        return self.vectorized_gaussian_logpdf(theta_spec,self.mu_vec,self.cov_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc2dcc-158f-42c6-8a26-643ec76ffd69",
   "metadata": {},
   "source": [
    "And, finally, the population model itself. Needs parallelization, everything moved to cupy, and to be wrapped such that it can be passed to Eryn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f21dd9b-16aa-4981-a160-2daf6ce7f78a",
   "metadata": {},
   "source": [
    "### IMPORTANT NOTE -- The version here does not return the specific indices of the resolved binaries for the sake of simple optimization. \n",
    "\n",
    "Depending on how we want to handle interaction with the resolved binaries, this may needto be rethought. That being said, I am at present increasingly convinced that the specific tail draws that represent resolved binaries are not actually useful beyond allowing us to marginalize over specific realizations to get statistics on $N_{\\rm res}(f_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3c155cc-95cd-418d-9cbc-d0e8000aa164",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopulationHyperPrior():\n",
    "    '''\n",
    "    Class for the actual hyperparameters.\n",
    "    '''\n",
    "\n",
    "    def __init__(self,hyperprior_dict=None):\n",
    "\n",
    "        '''.\n",
    "        For now, set defaults but we can adjust later.\n",
    "        '''\n",
    "\n",
    "        if hyperprior_dict is None:\n",
    "\n",
    "            hyperprior_dict = {'m_mu':xst.norm(loc=0.6,scale=0.05),\n",
    "                               'm_sigma':xst.invgamma(5),\n",
    "                               'd_gamma_a':xst.uniform(loc=1,scale=9), ## these are pretty arbitrary\n",
    "                               'd_gamma_b':xst.uniform(loc=1,scale=9), ## these are pretty arbitrary\n",
    "                               'a_alpha':xst.uniform(0.25,1.0)\n",
    "                              }\n",
    "        self.hyperprior_dict = hyperprior_dict\n",
    "        return\n",
    "\n",
    "    def sample(self,N=1):\n",
    "        return {key:self.hyperprior_dict[key].rvs(size=N) for key in self.hyperprior_dict.keys()}\n",
    "\n",
    "class PopModel():\n",
    "    '''\n",
    "    Class to house the overall population model.\n",
    "    '''\n",
    "\n",
    "    def __init__(self,Ntot,rng,fbins='default',Tobs=4*u.yr,Nsamp=1):\n",
    "        \n",
    "        self.hyperprior = PopulationHyperPrior()\n",
    "\n",
    "        self.gbprior = GalacticBinaryPrior(rng)\n",
    "\n",
    "        self.N = int(Ntot)\n",
    "\n",
    "        if type(fbins) is str and fbins == 'default':\n",
    "            self.bin_width = 1e-5\n",
    "            dur_eff = 1/bin_width\n",
    "            self.fbins = xp.arange(1e-4,5e-3,bin_width)\n",
    "        else:\n",
    "            self.fbins = fbins\n",
    "            self.bin_width = self.fbins[1] - self.fbins[0]\n",
    "\n",
    "        self.Tobs = Tobs.to(u.s).value\n",
    "\n",
    "        self.approx_lisa_psd = lw.psd.lisa_psd(self.fbins*u.Hz,t_obs=self.Tobs*u.s,confusion_noise=None).value\n",
    "\n",
    "        self.approx_lisa_rx = lw.psd.approximate_response_function(self.fbins*u.Hz,19.09*u.mHz).value\n",
    "\n",
    "        self.Nsamp = Nsamp\n",
    "\n",
    "        ## wrap the per-frequency bin and sort in xp.vectorize\n",
    "        self.vectorized_f_sort = np.vectorize(self.f_sort_wrapper,excluded=[1,2,4,5,6])   \n",
    "        \n",
    "        return\n",
    "\n",
    "    def construct_likelihood(self,data):\n",
    "        '''\n",
    "        Wrapper to build all the likelihoods\n",
    "        '''\n",
    "\n",
    "        fg_data = data['fg']\n",
    "        fg_sigma =data['fg_sigma']\n",
    "        N_res_data = data['Nres']\n",
    "\n",
    "        self.construct_fg_likelihood(fg_data,fg_sigma)\n",
    "        self.construct_Nres_likelihood(N_res_data)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def construct_fg_likelihood(self,fg_data,fg_sigma):\n",
    "        '''\n",
    "        Method to attach the foreground likelihood to the PopModel,\n",
    "        '''\n",
    "\n",
    "        self.fg_like = FG_Likelihood(fg_data,fg_sigma)\n",
    "        self.fg_ln_prob = self.fg_like.ln_prob\n",
    "\n",
    "        return\n",
    "\n",
    "    def construct_Nres_likelihood(self,N_res_obs):\n",
    "        '''\n",
    "        Method to attach the Poisson likelihood for the number of resolved binaries to the PopModel\n",
    "        '''\n",
    "        self.Nres_like = Nres_Likelihood(N_res_obs)\n",
    "        self.N_res_ln_prob = self.Nres_like.ln_prob\n",
    "\n",
    "        return\n",
    "        \n",
    "        \n",
    "            \n",
    "    @staticmethod\n",
    "    def rebin_calc_Nij(A, noisePSD, lowamp_PSD, wts, duration, duration_eff):\n",
    "        '''\n",
    "        Make the per-frequency SNR vector (dim 1xN_dwd)\n",
    "        \n",
    "        Arguments\n",
    "        ------------\n",
    "        A (float array)      : Sorted (ascending) DWD amplitudes\n",
    "        noisePSD (float)     : Level of the noise PSD in the relevant frequency bin (i.e., S_n(f))\n",
    "        lowamp_PSD (float)   : Level of the low-amplitude contribution to the foreground PSD in the relevant frequency bin\n",
    "        wts (float or array) : weights from fiducial population (1 for now)\n",
    "        duration (float)     : duration in seconds of the observing run. Assume 4 years in general.\n",
    "        duration_eff (float) : Effective duration in seconds given the frequency binning, i.e. 1/f_bin_width\n",
    "        '''\n",
    "        return xp.sqrt(duration*A**2/((noisePSD + lowamp_PSD + duration_eff * (xp.cumsum(wts*A**2) - wts*A**2) )))\n",
    "\n",
    "    @staticmethod\n",
    "    def f_sort_wrapper(i,f_idx,dwd_amps,LISA_rx,wts,snr_thresh,compute_frac,duration,duration_eff,noisePSD):\n",
    "        '''\n",
    "        Wrapper function for the iteration over frequencies of the rapid sort/threshold algorithm.\n",
    "\n",
    "        Arguments\n",
    "        ---------------\n",
    "\n",
    "\n",
    "        Returns\n",
    "        ---------------\n",
    "        foreground_amp_i (1 x Nf array)\n",
    "        N_res_i (int)\n",
    "        \n",
    "        '''\n",
    "\n",
    "        fbin_mask_i = xp.array(f_idx == i)\n",
    "        fbin_amps_i = dwd_amps[fbin_mask_i]*xp.sqrt(LISA_rx) ## sqrt because we square the amplitudes to get Sgw\n",
    "        fbin_sort_i = xp.argsort(fbin_amps_i)\n",
    "        re_sort_i = xp.argsort(fbin_sort_i) ## this will allow us to later return to the original order\n",
    "        sorted_fbin_amps_i = fbin_amps_i[fbin_sort_i]\n",
    "        if len(sorted_fbin_amps_i) != 0:\n",
    "            hightail_filt = sorted_fbin_amps_i > sorted_fbin_amps_i[int((1-compute_frac)*len(sorted_fbin_amps_i))]\n",
    "            # print(xp.sum(hightail_filt)/len(sorted_fbin_amps_i))\n",
    "            hightail_idx = xp.where(hightail_filt)\n",
    "            lowamp_idx = xp.where(xp.invert(hightail_filt))\n",
    "            # bin_amps_i[fbin_sort_i] > xp.quantile(fbin_amps_i[fbin_sort_i],0.9)\n",
    "            lowamp_PSD = duration_eff*xp.sum(wts*sorted_fbin_amps_i[xp.invert(hightail_filt)]**2)\n",
    "            # print(lowamp_PSD,noisePSD[i])\n",
    "            \n",
    "            high_tail = sorted_fbin_amps_i[hightail_filt]\n",
    "            \n",
    "            fbin_Nij = PopModel.rebin_calc_Nij(high_tail,noisePSD,lowamp_PSD,wts,duration,duration_eff)\n",
    "            # if fbin_Nij.size > 0:\n",
    "                # print(xp.max(fbin_Nij))\n",
    "            res_mask_i = xp.zeros(len(sorted_fbin_amps_i),dtype='bool')\n",
    "            res_mask_i = res_mask_i.at[hightail_idx].set(fbin_Nij>=snr_thresh)\n",
    "\n",
    "            ## get the number of resolved binaries in this bin\n",
    "            N_res_i = xp.sum(fbin_Nij>=snr_thresh)\n",
    "            \n",
    "            # print(xp.sum(res_mask_i))\n",
    "            res_mask_i_resort = res_mask_i[re_sort_i]\n",
    "            # fbin_res_list.append(dwd_idx[fbin_mask_i][res_mask_i_resort])\n",
    "            \n",
    "            foreground_amp_i = xp.sum(fbin_amps_i[xp.invert(res_mask_i_resort)]**2)\n",
    "        else:\n",
    "            foreground_amp_i = 0.0\n",
    "            N_res_i = 0\n",
    "\n",
    "        return foreground_amp_i, N_res_i\n",
    "    \n",
    "    def rebin_sort_threshold(self,binaries,fs,noisePSD,duration,LISA_rx,wts=1,snr_thresh=7,compute_frac=0.1):\n",
    "        '''\n",
    "        Function to bin by frequency, then for the vector of binaries in each frequency bin, sort them by amplitude.\n",
    "        \n",
    "        Arguments\n",
    "        -----------\n",
    "        binaries (dataframe) : df with binary info. Will rephrase arguments in terms of the specific needed components later.\n",
    "        fs (float array) : data frequencies\n",
    "        noisePSD  (float)     : Level of the noise PSD in the relevant frequency bin (i.e., S_n(f))\n",
    "        LISA_rx (float or array) : Approximate LISA response function evaluated at fs_full\n",
    "        wts (float or array) : weights from fiducial population (1 for now)\n",
    "        snr_thresh (float)    : the SNR threshold to condition resolved vs. unresolved on\n",
    "        quantile (float : Percent (from bottom) of sources in a given bin to assume are unresolved. Must be 0 < q < 1.\n",
    "        \n",
    "        Returns\n",
    "        -----------\n",
    "        foreground_amp (array) : Stochastic foreground from unresolved sources, evaluated at fs_full.\n",
    "        N_res (int)            : Number of resolved DWDs\n",
    "        res_idx (array)        : Indices of the binaries dataframe for resolved DWDs.\n",
    "        unres_idx (array)      : Indices of the binaries dataframe for unresolved DWDs.\n",
    "        '''\n",
    "        # dwd_fs = xp.array(binaries['fs'])\n",
    "        # dwd_amps = xp.array(binaries['hs'])\n",
    "    \n",
    "        dwd_fs = binaries[0,:]\n",
    "        dwd_amps = binaries[1,:]\n",
    "        \n",
    "        dwd_idx = xp.arange(len(dwd_amps))\n",
    "        ## constrain to frequencies where we have a noise curve\n",
    "        fs_noise = fs ## lazy\n",
    "        fs_full = fs ## lazy\n",
    "        if fs_noise[0] == 0:\n",
    "            fs_noise = fs_noise[1:]\n",
    "            noisePSD = noisePSD[1:]\n",
    "        noise_f_mask = (fs_full>=fs_noise.min()) & (fs_full<=fs_noise.max())\n",
    "        fs_full = fs_full[noise_f_mask]\n",
    "        ## find which noise frequency corresponds to each frequency bin\n",
    "    #     noise_f_idx = xp.digitize(fs_full,fs_noise-(fs_noise[1]-fs_noise[0])/2)\n",
    "        \n",
    "        ## bin the binaries by frequency\n",
    "        ## first, find which frequency bin each binary is in\n",
    "        delf = fs_full[1] - fs_full[0]\n",
    "        f_idx = xp.digitize(dwd_fs,fs_full+0.5*delf)\n",
    "        duration_eff = 1/delf ## effective duration for new frequency resolution\n",
    "        \n",
    "        ## now created a ragged list of arrays of varying sizes, corresponding to N_dwd(f_i)\n",
    "        ## each entry is an array containing the indices of the DWDs in that bin, sorted by ascending amplitude*\n",
    "        ##     * under the current assumption of uniform responses, this is equivalent to sorting by the naive SNR\n",
    "        ##       (!! -- we will need to refine this in future)\n",
    "        # fbin_res_list = []\n",
    "        # foreground_amp = xp.zeros(len(fs_full))\n",
    "        # iter_range = len(fs_full)\n",
    "\n",
    "        \n",
    "        ## these should be 1 x Nf arrays, where Nf is the number of frequency bins\n",
    "        foreground_amp, N_res = self.vectorized_f_sort(xp.arange(fs_full.shape[0]),f_idx,dwd_amps,\n",
    "                                                  LISA_rx,wts,snr_thresh,compute_frac,duration,duration_eff,noisePSD)\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "        # ##unpack the binned list\n",
    "        # res_idx = xp.array([],dtype=int)\n",
    "        # for i, arr in enumerate(fbin_res_list):\n",
    "        #     res_idx = xp.append(res_idx,arr)\n",
    "        # N_res = len(res_idx)\n",
    "        # unres_idx = xp.isin(dwd_idx,res_idx,invert=True)\n",
    "        \n",
    "        return foreground_amp, N_res\n",
    "\n",
    "    \n",
    "    def run_model(self,pop_theta=None):\n",
    "\n",
    "        ## draw pop hyperparameters\n",
    "        if pop_theta is None:\n",
    "            pop_theta = self.hyperprior.sample(1)\n",
    "\n",
    "        ## condition the astro parameter distributions on the hyperprior draw\n",
    "        self.gbprior.condition(pop_theta)\n",
    "\n",
    "        ## draw a sample galaxy\n",
    "        galaxy_draw = self.gbprior.sample_conditional(self.N)\n",
    "\n",
    "        ## convert to phenomenological space\n",
    "        amp_draws, fgw_draws = get_amp_freq(galaxy_draw)\n",
    "\n",
    "        ## form array\n",
    "        obs_draws = xp.array([fgw_draws,amp_draws])\n",
    "        \n",
    "        ## sort into resolved and unresolved binaries\n",
    "        fg_sort, fs_sort, N_res, res_idx, unres_idx = self.rebin_sort_threshold(obs_draws,\n",
    "                                                                           self.fbins,\n",
    "                                                                           self.approx_lisa_psd,\n",
    "                                                                           self.Tobs,\n",
    "                                                                           self.approx_lisa_rx,\n",
    "                                                                           wts=1,\n",
    "                                                                           snr_thresh=7,\n",
    "                                                                           compute_frac=0.2)\n",
    "        fg_psd = (self.Tobs / self.bin_width**(-1))*fg_sort\n",
    "\n",
    "        ## lowest bin is not accurate, discard\n",
    "        return self.fbins[1:], fg_psd[1:], N_res, res_idx\n",
    "\n",
    "    def fg_N_ln_prob(self,pop_theta,return_spec=False):\n",
    "        '''\n",
    "        Function to get the model probability conditioned on only \n",
    "        the per-bin foreground amplitude and the total number of resolved binaries\n",
    "\n",
    "        Eventually we can extend this to per-bin N_res\n",
    "        '''\n",
    "        # ## unpack data\n",
    "        # N_res_obs = data['N_res']\n",
    "        # fg_obs = data['fg']\n",
    "\n",
    "        ## call the population model\n",
    "        fbins, fg_psd, N_res = self.run_model(pop_theta)\n",
    "\n",
    "        ## call the fg likelihood\n",
    "        ln_p_fg = self.fg_ln_prob(fg_psd)\n",
    "\n",
    "        ln_p_Nres = self.N_res_ln_prob(N_res)\n",
    "\n",
    "        if return_spec:\n",
    "            return xp.append(xp.append(fg_psd,N_res),xp.array([ln_p_fg + ln_p_Nres]))\n",
    "        else:\n",
    "            return ln_p_fg + ln_p_Nres\n",
    "\n",
    "    def sample_likelihood(self,save_spec=False):\n",
    "\n",
    "        ## the chain dimension should be the number of pop params + 2x the number of frequency bins + 1\n",
    "        ## so we can store the pop params, the foreground spectra, N_res(f_i), and the likelihood\n",
    "        Npar = len(self.hyperprior.hyperprior_dict)\n",
    "        Nf = len(self.fbins)\n",
    "        chain_dim = Npar + 2*Nf + 1\n",
    "        \n",
    "        new_chain = xp.empty((chain_dim,self.Nsamp)) ## last column is for the likelihood\n",
    "        if hasattr(self,'chain'):\n",
    "            self.chain = xp.append(self.chain,new_chain,axis=1)\n",
    "        else:\n",
    "            self.chain = new_chain\n",
    "\n",
    "        \n",
    "        if save_spec:\n",
    "            for ii in tqdm(range(self.Nsamp)):\n",
    "                draw = self.hyperprior.sample(1)\n",
    "                self.chain = self.chain.at[:Npar,ii].set(xp.array([draw[key] for key in draw.keys()]).flatten())\n",
    "                self.chain = self.chain.at[Npar:,ii].set(self.fg_N_ln_prob(draw,return_spec=True,return_N=True))\n",
    "            return self.chain\n",
    "        \n",
    "        else:\n",
    "            for ii in tqdm(range(self.Nsamp)):\n",
    "                draw = self.hyperprior.sample(1)\n",
    "                self.chain[:-1,ii] = xp.array([draw[key] for key in draw.keys()]).flatten()\n",
    "                self.chain[-1,ii] = self.fg_N_ln_prob(draw)\n",
    "        \n",
    "            \n",
    "            return self.chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11aeaba2-0ec2-4c5c-831f-bf6f4f0bcb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_rng = jax.random.key(42)\n",
    "test_rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb2ce843-481b-4a14-af89-3bd0d699f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test frequency bins\n",
    "bin_width = 1e-5\n",
    "dur_eff = 1/bin_width\n",
    "f_bins = xp.arange(1e-4,1e-3,bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8353a0d1-3d18-4b0a-9a96-8e70bca5fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_popmodel = PopModel(1e7,test_rng,fbins=f_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e219f693-f870-4531-b8e0-f2eaecf8330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0805 14:43:16.164726    4105 hlo_lexer.cc:443] Failed to parse int literal: 13328992393196351600448\n",
      "E0805 14:43:16.164777    4105 hlo_lexer.cc:443] Failed to parse int literal: 13328992393196351600448\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mXlaRuntimeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:2795\u001b[39m, in \u001b[36m_cached_compilation\u001b[39m\u001b[34m(computation, name, mesh, spmd_lowering, tuple_args, auto_spmd_lowering, allow_prop_to_inputs, allow_prop_to_outputs, host_callbacks, backend, da, pmap_nreps, compiler_options_kvs, pgle_profiler)\u001b[39m\n\u001b[32m   2792\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dispatch.log_elapsed_time(\n\u001b[32m   2793\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFinished XLA compilation of \u001b[39m\u001b[38;5;132;01m{fun_name}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{elapsed_time:.9f}\u001b[39;00m\u001b[33m sec\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2794\u001b[39m     fun_name=name, event=dispatch.BACKEND_COMPILE_EVENT):\n\u001b[32m-> \u001b[39m\u001b[32m2795\u001b[39m   xla_executable = \u001b[43mcompiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_or_get_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2796\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2797\u001b[39m \u001b[43m      \u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2798\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xla_executable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/jax/_src/compiler.py:432\u001b[39m, in \u001b[36mcompile_or_get_cached\u001b[39m\u001b[34m(backend, computation, devices, compile_options, host_callbacks, pgle_profiler)\u001b[39m\n\u001b[32m    431\u001b[39m log_persistent_cache_miss(module_name, cache_key)\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_and_write_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/jax/_src/compiler.py:694\u001b[39m, in \u001b[36m_compile_and_write_cache\u001b[39m\u001b[34m(backend, computation, compile_options, host_callbacks, module_name, cache_key)\u001b[39m\n\u001b[32m    693\u001b[39m start_time = time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m694\u001b[39m executable = \u001b[43mbackend_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m compile_time = time.monotonic() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/jax/_src/profiler.py:334\u001b[39m, in \u001b[36mannotate_function.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, **decorator_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/jax/_src/compiler.py:330\u001b[39m, in \u001b[36mbackend_compile\u001b[39m\u001b[34m(backend, module, options, host_callbacks)\u001b[39m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m handler_result \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/jax/_src/compiler.py:324\u001b[39m, in \u001b[36mbackend_compile\u001b[39m\u001b[34m(backend, module, options, host_callbacks)\u001b[39m\n\u001b[32m    321\u001b[39m   \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[32m    322\u001b[39m   \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[32m    323\u001b[39m   \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m xc.XlaRuntimeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mXlaRuntimeError\u001b[39m: INTERNAL: ptxas exited with non-zero error code 2, output: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test_fg, N_res = \u001b[43mtest_popmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 253\u001b[39m, in \u001b[36mPopModel.run_model\u001b[39m\u001b[34m(self, pop_theta)\u001b[39m\n\u001b[32m    250\u001b[39m obs_draws = xp.array([fgw_draws,amp_draws])\n\u001b[32m    252\u001b[39m \u001b[38;5;66;03m## sort into resolved and unresolved binaries\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m fg_sort, fs_sort, N_res, res_idx, unres_idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrebin_sort_threshold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_draws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m                                                                   \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfbins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m                                                                   \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapprox_lisa_psd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m                                                                   \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mTobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m                                                                   \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapprox_lisa_rx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m                                                                   \u001b[49m\u001b[43mwts\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m                                                                   \u001b[49m\u001b[43msnr_thresh\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m                                                                   \u001b[49m\u001b[43mcompute_frac\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m fg_psd = (\u001b[38;5;28mself\u001b[39m.Tobs / \u001b[38;5;28mself\u001b[39m.bin_width**(-\u001b[32m1\u001b[39m))*fg_sort\n\u001b[32m    263\u001b[39m \u001b[38;5;66;03m## lowest bin is not accurate, discard\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 218\u001b[39m, in \u001b[36mPopModel.rebin_sort_threshold\u001b[39m\u001b[34m(self, binaries, fs, noisePSD, duration, LISA_rx, wts, snr_thresh, compute_frac)\u001b[39m\n\u001b[32m    206\u001b[39m duration_eff = \u001b[32m1\u001b[39m/delf \u001b[38;5;66;03m## effective duration for new frequency resolution\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m## now created a ragged list of arrays of varying sizes, corresponding to N_dwd(f_i)\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m## each entry is an array containing the indices of the DWDs in that bin, sorted by ascending amplitude*\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m##     * under the current assumption of uniform responses, this is equivalent to sorting by the naive SNR\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    216\u001b[39m \n\u001b[32m    217\u001b[39m \u001b[38;5;66;03m## these should be 1 x Nf arrays, where Nf is the number of frequency bins\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m foreground_amp, N_res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorized_f_sort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs_full\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mf_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdwd_amps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m                                          \u001b[49m\u001b[43mLISA_rx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwts\u001b[49m\u001b[43m,\u001b[49m\u001b[43msnr_thresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcompute_frac\u001b[49m\u001b[43m,\u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43mduration_eff\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnoisePSD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[38;5;66;03m# ##unpack the binned list\u001b[39;00m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# res_idx = xp.array([],dtype=int)\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# for i, arr in enumerate(fbin_res_list):\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[38;5;66;03m#     res_idx = xp.append(res_idx,arr)\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# N_res = len(res_idx)\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[38;5;66;03m# unres_idx = xp.isin(dwd_idx,res_idx,invert=True)\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m foreground_amp, N_res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/numpy/lib/function_base.py:2372\u001b[39m, in \u001b[36mvectorize.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   2369\u001b[39m     \u001b[38;5;28mself\u001b[39m._init_stage_2(*args, **kwargs)\n\u001b[32m   2370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2372\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_as_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/numpy/lib/function_base.py:2365\u001b[39m, in \u001b[36mvectorize._call_as_normal\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   2362\u001b[39m     vargs = [args[_i] \u001b[38;5;28;01mfor\u001b[39;00m _i \u001b[38;5;129;01min\u001b[39;00m inds]\n\u001b[32m   2363\u001b[39m     vargs.extend([kwargs[_n] \u001b[38;5;28;01mfor\u001b[39;00m _n \u001b[38;5;129;01min\u001b[39;00m names])\n\u001b[32m-> \u001b[39m\u001b[32m2365\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_vectorize_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/numpy/lib/function_base.py:2455\u001b[39m, in \u001b[36mvectorize._vectorize_call\u001b[39m\u001b[34m(self, func, args)\u001b[39m\n\u001b[32m   2452\u001b[39m \u001b[38;5;66;03m# Convert args to object arrays first\u001b[39;00m\n\u001b[32m   2453\u001b[39m inputs = [asanyarray(a, dtype=\u001b[38;5;28mobject\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[32m-> \u001b[39m\u001b[32m2455\u001b[39m outputs = \u001b[43mufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2457\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ufunc.nout == \u001b[32m1\u001b[39m:\n\u001b[32m   2458\u001b[39m     res = asanyarray(outputs, dtype=otypes[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/numpy/lib/function_base.py:2360\u001b[39m, in \u001b[36mvectorize._call_as_normal.<locals>.func\u001b[39m\u001b[34m(*vargs)\u001b[39m\n\u001b[32m   2358\u001b[39m     the_args[_i] = vargs[_n]\n\u001b[32m   2359\u001b[39m kwargs.update(\u001b[38;5;28mzip\u001b[39m(names, vargs[\u001b[38;5;28mlen\u001b[39m(inds):]))\n\u001b[32m-> \u001b[39m\u001b[32m2360\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpyfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mthe_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 143\u001b[39m, in \u001b[36mPopModel.f_sort_wrapper\u001b[39m\u001b[34m(i, f_idx, dwd_amps, LISA_rx, wts, snr_thresh, compute_frac, duration, duration_eff, noisePSD)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# print(lowamp_PSD,noisePSD[i])\u001b[39;00m\n\u001b[32m    141\u001b[39m high_tail = sorted_fbin_amps_i[hightail_filt]\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m fbin_Nij = \u001b[43mPopModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrebin_calc_Nij\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhigh_tail\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnoisePSD\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlowamp_PSD\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwts\u001b[49m\u001b[43m,\u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43mduration_eff\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[38;5;66;03m# if fbin_Nij.size > 0:\u001b[39;00m\n\u001b[32m    145\u001b[39m     \u001b[38;5;66;03m# print(xp.max(fbin_Nij))\u001b[39;00m\n\u001b[32m    146\u001b[39m res_mask_i = xp.zeros(\u001b[38;5;28mlen\u001b[39m(sorted_fbin_amps_i),dtype=\u001b[33m'\u001b[39m\u001b[33mbool\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 109\u001b[39m, in \u001b[36mPopModel.rebin_calc_Nij\u001b[39m\u001b[34m(A, noisePSD, lowamp_PSD, wts, duration, duration_eff)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrebin_calc_Nij\u001b[39m(A, noisePSD, lowamp_PSD, wts, duration, duration_eff):\n\u001b[32m     97\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[33;03m    Make the per-frequency SNR vector (dim 1xN_dwd)\u001b[39;00m\n\u001b[32m     99\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \u001b[33;03m    duration_eff (float) : Effective duration in seconds given the frequency binning, i.e. 1/f_bin_width\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m xp.sqrt(duration*A**\u001b[32m2\u001b[39m/((noisePSD + lowamp_PSD + duration_eff * (\u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwts\u001b[49m\u001b[43m*\u001b[49m\u001b[43mA\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mwts\u001b[49m\u001b[43m*\u001b[49m\u001b[43mA\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m2\u001b[39;49m) )))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:579\u001b[39m, in \u001b[36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    577\u001b[39m args = (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[32m    581\u001b[39m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/jax/_src/numpy/ufunc_api.py:180\u001b[39m, in \u001b[36mufunc.__call__\u001b[39m\u001b[34m(self, out, where, *args)\u001b[39m\n\u001b[32m    178\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwhere argument of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    179\u001b[39m call = \u001b[38;5;28mself\u001b[39m.__static_props[\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_vectorized\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/jax/_src/pjit.py:340\u001b[39m, in \u001b[36m_cpp_pjit.<locals>.cache_miss\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.no_tracing.value:\n\u001b[32m    336\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mre-tracing function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjit_info.fun_sourceinfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    337\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33m`jit`, but \u001b[39m\u001b[33m'\u001b[39m\u001b[33mno_tracing\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is set\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    339\u001b[39m (outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked, executable,\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m  pgle_profiler) = \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m maybe_fastpath_data = _get_fastpath_data(\n\u001b[32m    343\u001b[39m     executable, out_tree, args_flat, out_flat, attrs_tracked, jaxpr.effects,\n\u001b[32m    344\u001b[39m     jaxpr.consts, jit_info.abstracted_axes,\n\u001b[32m    345\u001b[39m     pgle_profiler)\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outs, maybe_fastpath_data, _need_to_rebuild_with_fdo(pgle_profiler)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/jax/_src/pjit.py:191\u001b[39m, in \u001b[36m_python_pjit_helper\u001b[39m\u001b[34m(fun, jit_info, *args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m   args_flat = \u001b[38;5;28mmap\u001b[39m(core.full_lower, args_flat)\n\u001b[32m    190\u001b[39m   core.check_eval_args(args_flat)\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m   out_flat, compiled, profiler = \u001b[43m_pjit_call_impl_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    193\u001b[39m   out_flat = pjit_p.bind(*args_flat, **p.params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/jax/_src/pjit.py:1809\u001b[39m, in \u001b[36m_pjit_call_impl_python\u001b[39m\u001b[34m(jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, donated_invars, ctx_mesh, name, keep_unused, inline, compiler_options_kvs, *args)\u001b[39m\n\u001b[32m   1797\u001b[39m compiler_options_kvs = compiler_options_kvs + \u001b[38;5;28mtuple\u001b[39m(pgle_compile_options.items())\n\u001b[32m   1798\u001b[39m \u001b[38;5;66;03m# Passing mutable PGLE profile here since it should be extracted by JAXPR to\u001b[39;00m\n\u001b[32m   1799\u001b[39m \u001b[38;5;66;03m# initialize the fdo_profile compile option.\u001b[39;00m\n\u001b[32m   1800\u001b[39m compiled = \u001b[43m_resolve_and_lower\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1801\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m=\u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_layouts\u001b[49m\u001b[43m=\u001b[49m\u001b[43min_layouts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1804\u001b[39m \u001b[43m    \u001b[49m\u001b[43mctx_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mctx_mesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1805\u001b[39m \u001b[43m    \u001b[49m\u001b[43minline\u001b[49m\u001b[43m=\u001b[49m\u001b[43minline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlowering_platforms\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlowering_parameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlir\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLoweringParameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1807\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1808\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1809\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1811\u001b[39m \u001b[38;5;66;03m# This check is expensive so only do it if enable_checks is on.\u001b[39;00m\n\u001b[32m   1812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compiled._auto_spmd_lowering \u001b[38;5;129;01mand\u001b[39;00m config.enable_checks.value:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:2462\u001b[39m, in \u001b[36mMeshComputation.compile\u001b[39m\u001b[34m(self, compiler_options)\u001b[39m\n\u001b[32m   2460\u001b[39m compiler_options_kvs = \u001b[38;5;28mself\u001b[39m._compiler_options_kvs + t_compiler_options\n\u001b[32m   2461\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._executable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m compiler_options_kvs:\n\u001b[32m-> \u001b[39m\u001b[32m2462\u001b[39m   executable = \u001b[43mUnloadedMeshExecutable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_hlo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2463\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_hlo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompile_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2464\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2465\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compiler_options_kvs:\n\u001b[32m   2466\u001b[39m     \u001b[38;5;28mself\u001b[39m._executable = executable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:3004\u001b[39m, in \u001b[36mUnloadedMeshExecutable.from_hlo\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   3001\u001b[39m       \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   3003\u001b[39m util.test_event(\u001b[33m\"\u001b[39m\u001b[33mpxla_cached_compilation\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m3004\u001b[39m xla_executable = \u001b[43m_cached_compilation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhlo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspmd_lowering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtuple_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_spmd_lowering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_prop_to_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3007\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_prop_to_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmap_nreps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3008\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3010\u001b[39m orig_out_shardings = out_shardings\n\u001b[32m   3012\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m auto_spmd_lowering:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:2792\u001b[39m, in \u001b[36m_cached_compilation\u001b[39m\u001b[34m(computation, name, mesh, spmd_lowering, tuple_args, auto_spmd_lowering, allow_prop_to_inputs, allow_prop_to_outputs, host_callbacks, backend, da, pmap_nreps, compiler_options_kvs, pgle_profiler)\u001b[39m\n\u001b[32m   2785\u001b[39m compiler_options = \u001b[38;5;28mdict\u001b[39m(compiler_options_kvs)\n\u001b[32m   2787\u001b[39m compile_options = create_compile_options(\n\u001b[32m   2788\u001b[39m     computation, mesh, spmd_lowering, tuple_args, auto_spmd_lowering,\n\u001b[32m   2789\u001b[39m     allow_prop_to_inputs, allow_prop_to_outputs, backend,\n\u001b[32m   2790\u001b[39m     dev, pmap_nreps, compiler_options)\n\u001b[32m-> \u001b[39m\u001b[32m2792\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dispatch.log_elapsed_time(\n\u001b[32m   2793\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFinished XLA compilation of \u001b[39m\u001b[38;5;132;01m{fun_name}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{elapsed_time:.9f}\u001b[39;00m\u001b[33m sec\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2794\u001b[39m     fun_name=name, event=dispatch.BACKEND_COMPILE_EVENT):\n\u001b[32m   2795\u001b[39m   xla_executable = compiler.compile_or_get_cached(\n\u001b[32m   2796\u001b[39m       backend, computation, dev, compile_options, host_callbacks,\n\u001b[32m   2797\u001b[39m       pgle_profiler)\n\u001b[32m   2798\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xla_executable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mamba/envs/gwenv-1/lib/python3.12/site-packages/jax/_src/dispatch.py:183\u001b[39m, in \u001b[36mLogElapsedTimeContextManager.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    181\u001b[39m   \u001b[38;5;28mself\u001b[39m.start_time = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[32m    184\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _on_exit:\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "test_fg, N_res = test_popmodel.run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90c4dd-c73a-492a-9a67-2c612536b038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3587e9c-b27a-4ced-9042-5478f428a5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb321e-55c6-474a-8b65-916b81c83e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9edfb6-20da-4e9d-86cd-458ad40d5882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gwenv-1",
   "language": "python",
   "name": "gwenv-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
